# Bike Sharing Demand Forecasting  
This repository contains the project for **D100 / D400 – Fundamentals of Data Science & Research Computing (Michaelmas 2025)**.

---

## Project Overview

This project implements an end-to-end **prediction-focused data science workflow** to forecast 
**hourly system-level bike rental demand** using the Seoul Bike Sharing Demand dataset. Also, the analysis 
aims to generate **operationally relevant insights** into how demand varies across time and weather conditions, 
supporting more informed decisions on capacity planning and system-level resource allocation.


The project is developed as part of the **combined D100 / D400 assessment** and implements a
complete data science workflow, including:
- reproducible data loading and cleaning,
- structured exploratory data analysis (EDA) to understand the data,
- model training using two complementary approaches: a parametric GLM and a non-parametric LightGBM,
- hyperparameter tuning via cross-validation,
- model evaluation and interpretability using standard diagnostic tools.


The repository is structured as an installable Python package and is designed to run **out-of-the-box**, 
with emphasis on reproducibility, clarity, and interpretability.

---

## Dataset

The analysis uses the **Seoul Bike Sharing Demand** dataset from the
[UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/560/seoul+bike+sharing+demand).


- 8,760 hourly observations (24 × 365)
- Period: 1 December 2017 – 30 November 2018
- Target variable: hourly number of rented bikes
- Features include:
  - temporal variables (hour, season),
  - environmental conditions (temperature, humidity, wind speed, rainfall, snowfall, etc.),
  - calendar indicators (holiday, functioning day).

The dataset contains no missing values. No observations are removed during cleaning, as extreme
values reflect genuine demand variation and operational conditions rather than data errors.

---

## Repository Structure

```text
.
├── data/
│   ├── raw/                        # Raw dataset
│   └── processed/                  # Cleaned dataset generated by the pipeline (.parquet, not tracked by Git)
│
├── notebooks/
│   └── eda_cleaning.ipynb           # Exploratory data analysis & data understanding
│
├── src/bike_demand/
│   ├── data/
│   │   └── load_data.py             # Data loading utilities
│   │
│   ├── feature_engineering/
│   │   └── transformers.py          # Custom scikit-learn transformer
│   │
│   ├── modelling/
│   │   ├── sample_split.py          # Deterministic train/validation split (ID-based)
│   │   ├── glm_pipeline.py          # GLM pipeline 
│   │   └── lgbm_pipeline.py         # LightGBM pipeline
│   │
│   ├── evaluation/
│   │   └── metrics.py               # Evaluation metrics
│   │
│   ├── preprocessing.py             # Preprocessing steps for EDA
│   │
│   ├── plotting.py                  # Plotting utilities for exploratory analysis and model diagnostics
│   │
│   └── __init__.py
│
├── tests/
│   └── test_transformers.py          # Unit tests for custom transformer(s)
│
├── environment.yml
├── pyproject.toml
└── README.md
```


All reusable utilities are implemented in `src/`, while analysis scripts are responsible for model training and evaluation.
Best hyperparameters selected during training are reused directly in the evaluation stage.

---

## How to use these codes? (Environment Setup)

The project is developed and tested using **Python ≥ 3.11**.

### 1. Create the conda environment

```bash
conda env create -f environment.yml
conda activate d100_d400_code_1149Z
```

### 2. Install the project as a package

```bash
pip install -e .
```
Installing the project in editable mode ensures that all modules can be imported consistently across scripts and notebooks, 
and allows changes to the source code to be reflected immediately without reinstallation.


---

## Running the Project

### 1. Exploratory Data Analysis
Open and run:

```bash
notebooks/eda_cleaning.ipynb
```

This notebook:
- loads the raw dataset,
- performs exploratory data analysis to understand demand patterns and feature relationships,
- documents key data issues and modelling-relevant decisions (e.g. distributional properties, structural zeros),
- informs preprocessing and feature engineering choices used downstream.

The notebook is used for data understanding, while all preprocessing applied during modelling is implemented in 
reusable pipeline components.

### 2. Model Training and Evaluation

Model training and evaluation are orchestrated by analysis scripts that rely on reusable
utilities implemented in `src/` to ensure consistency and reproducibility.

In particular:
- reusable components are implemented in `src/` as modular subpackages (e.g. `feature_engineering/`), and are imported by the analysis scripts,
- model pipelines for the regularised GLM and LightGBM are defined in dedicated modules,
- a deterministic ID-based train/validation split is applied, 
- hyperparameters are tuned using cross-validation,
- best-performing hyperparameters are saved in json,
- evaluation metrics are defined in `evaluation/metrics.py`.
  
Running the analysis scripts in `analyses/` produces model performance metrics and diagnostic plots used in the report.

---

## Evaluation and Interpretability

Model performance is evaluated on a held-out validation set using:
- mean Tweedie deviance,
- RMSE and MAE,
- R²,
- predicted versus actual diagnostic plots.

Interpretability is addressed through:
- feature importance analysis,
- partial dependence plots for the most influential features,

Results are interpreted in terms of their operational relevance for understanding and anticipating
hourly demand variation, with particular attention to the comparative performance and behaviour
of the GLM and LightGBM models.

## Testing and Code Quality

Unit tests are provided for custom scikit-learn components to ensure correctness and robustness.

```bash
pytest
```

Code quality and consistency are enforced through:
- type hints and docstrings for improved readability and maintainability,
- automated linting and formatting via pre-commit hooks (e.g. `ruff`),
- notebook output stripping using `nbstripout` to keep version control clean.

